{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eldA-sl8YsLp"
   },
   "source": [
    "# Week 2: Principal Component Analysis\n",
    "\n",
    "\n",
    "In this workshop, we will work through a set of problems on dimensionality reduction -- a cannonical form of unsupervised learning. Within the machine learning pipeline, dimensionality reduction is an important tool, which can used in EDA to understand patterns in the data, feature engineering to create a low-dimensional representation of the inputs, and/or in the final phase when you are presenting and visualizing your solution.\n",
    "\n",
    "As usual, the worksheets will be completed in teams of 2-3, using **pair programming**, and we have provided cues to switch roles between driver and navigator. When completing worksheets:\n",
    "\n",
    ">- You will have tasks tagged by (CORE) and (EXTRA). \n",
    ">- Your primary aim is to complete the (CORE) components during the WS session, afterwards you can try to complete the (EXTRA) tasks for your self-learning process. \n",
    ">- Look for the 🏁 as cue to switch roles between driver and navigator.\n",
    ">- In some Exercises, you will see some beneficial hints at the bottom of questions.\n",
    "\n",
    "Instructions for submitting your workshops can be found at the end of worksheet. As a reminder, you must submit a pdf of your notebook on Learn by 16:00 PM on the Friday of the week the workshop was given. \n",
    "\n",
    "As you work through the problems it will help to refer to your lecture notes (navigator). The exercises here are designed to reinforce the topics covered this week. Please discuss with the tutors if you get stuck, even early on! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. [Problem Definition and Setup](#setup)\n",
    "\n",
    "2. [Principal Component Analysis](#pca)\n",
    "\n",
    "  a. [Examining the Basis Vectors and Scores](#basis)\n",
    "\n",
    "  b. [Selecting the Number of Components](#nocomponents)\n",
    "\n",
    "  c. [Other Digits](#other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm6XqPScK-FV"
   },
   "source": [
    "# Problem Definition and Setup <a id='setup'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "First, lets load in some packages to get us started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1674743647585,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "usEZAe6SYpV8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSj3Z820mFwv"
   },
   "source": [
    "## Data\n",
    "\n",
    "Our dataset will be the famous [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digits, which we will download from sklearn. The dataset consists of a set of greyscale images of the numbers 0-9 and corresponding labels. Usually the goal is to train a classifier (i.e. given an image, what digit does it correspond to?). Here we will throw away the labels and focus on the images themselves. Specifically, we will use dimensionality reduction to explore the images and underlying patterns and find a low-dimensional representation.\n",
    "\n",
    "First, load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784',parser = 'auto')\n",
    "X = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeHcm_OBGhtx"
   },
   "source": [
    "### 🚩 Exercise 1 (CORE)\n",
    "\n",
    "What is stored in `X` and `y` in the command above? What is the shape/datatype etc if an array?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q1xG24emmdu"
   },
   "source": [
    "Now, let's create a dictionary, with the digit classes (0-9) as keys, where the correponding values are the set of all images corresponding to that particular label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1674743872754,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "nCExrjAlmQOm"
   },
   "outputs": [],
   "source": [
    "digits_dict = {}\n",
    "X_= X.values\n",
    "count = 0\n",
    "\n",
    "for label in y:\n",
    "  if label in digits_dict:\n",
    "    digits_dict[label] += [X_[count]]\n",
    "  else:\n",
    "    digits_dict[label] = [X_[count]]\n",
    "  count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's visualize some of the images. We will start by picking a label and plotting a few images from within the dictionary. Note that each image contains a total of 784 pixels (28 by 28) and we will need to `reshape` the image to plot with `imshow(...,cmap='gray_r')`. Try also changing the label to view different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylabel = '1'\n",
    "n_images_per_label = 5\n",
    "\n",
    "fig = plt.figure(figsize=(4*n_images_per_label, 4))\n",
    "for j in range(n_images_per_label):\n",
    "    ax_number = 1 + j\n",
    "    ax = fig.add_subplot(1, n_images_per_label, ax_number)\n",
    "    ax.imshow(digits_dict[mylabel][j].reshape((28,28)), cmap='gray_r')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z95pdmrynwyX"
   },
   "source": [
    "### 🚩 Exercise 2 (EXTRA)\n",
    "\n",
    "Edit the code above to plot a few images for multiple labels.\n",
    "\n",
    "<br>\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "\n",
    "Create a vector of labels and add additional for loop in the code above.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 873
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1674743876957,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "98lyOLGKmjam",
    "outputId": "76cd9822-4e86-44d7-8bfe-7dfed42686fe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R_1TGs8rInz"
   },
   "source": [
    "### 🚩 Exercise 3 (CORE)\n",
    "\n",
    "Now focus on the 3s only and create a data matrix called `X_threes`. Define also `N` (# datapoints) and `D` (# features).\n",
    "\n",
    "What are the features in this problem? How many features and data points are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1674743879981,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "HhzuQdIuptAh",
    "outputId": "274c220d-7d32-4942-a82c-49909efceef0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAtBj2cRs6RZ"
   },
   "source": [
    "### 🚩 Exercise 4 (CORE)\n",
    "\n",
    "Now compute and plot the mean image of three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1674743895536,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "z3sD-Qyjs5vz",
    "outputId": "a32a5957-f43a-4e9c-8d34-7750f2e7e85b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to first create a new data matrix that centers the data by subtracting the mean image, and then visualise some of the images and compare to the original data. Note: you will need to replace `X_three_mean` with the name you gave the mean image in the computation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "executionInfo": {
     "elapsed": 849,
     "status": "ok",
     "timestamp": 1674743904757,
     "user": {
      "displayName": "Jacob Page",
      "userId": "04818256562649201928"
     },
     "user_tz": 0
    },
    "id": "Y3YJUQDIr_-G",
    "outputId": "d3cf35a0-db7d-4c25-b798-dfd013c16d49"
   },
   "outputs": [],
   "source": [
    "X_three_centred = X_threes - X_three_mean\n",
    "\n",
    "n_images = 5\n",
    "\n",
    "fig = plt.figure(figsize=(4*n_images, 4*2))\n",
    "for j in range(n_images):\n",
    "  ax = fig.add_subplot(2, n_images, j+1)\n",
    "  ax.imshow(X_three_centred[j,:].reshape((28,28)), cmap='gray_r')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "  ax = fig.add_subplot(2, n_images, j+1+n_images)\n",
    "  ax.imshow(X_threes[j,:].reshape((28,28)), cmap='gray_r')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 5 (CORE)\n",
    "\n",
    "Comment on whether or not the images need to be standardized before using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 **Now, is a good point to switch driver and navigator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA <a id='pca'></a>\n",
    "\n",
    "Now, we will perform PCA to summarize the main patterns in the images. We will use the [`PCA()`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) transform from the `sklearn.decomposition` package:\n",
    "\n",
    "- We can specify the number of components with the option `n_components`. If omitted, all components are kept.\n",
    "\n",
    "- Note that by default the `PCA()` transform centers the variables to have zero mean (but does not scale them). After fitting, we can access the mean through the attribute `mean_`. If we also want to standardize to have not only zero mean but also unit variance, we can set `whiten=True`.\n",
    "\n",
    "- We can access the basis vectors (principal components) through the `components_` attribute.\n",
    "\n",
    "- We can call `fit()` to fit the model, followed by `transform` to obtain the low-dimensional representation (or also `fit_transform`). \n",
    "\n",
    " First, let's create the PCA transform and call `fit()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_threes = PCA(n_components = 200)\n",
    "pca_threes.fit(X_threes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the Basis Vectors and Scores <a id='basis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 6 (EXTRA)\n",
    " \n",
    "Plot the mean image by accessing the `mean_` attribute and check that it is the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 7 (CORE)\n",
    "\n",
    "Plot the the first ten basis vectors as images by accessing the `components_` attribute. Overall, what patterns do they seem describe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 8 (CORE)\n",
    "\n",
    "a) Use the `transform()` method to compute the PCA scores and save them in an object called `scores`. Then, plot the data points in the low-dimensional space spanned by the first two principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better interpret the latent dimensions, let's look at some projected points along each dimension and the corresponding images. Specifically, run the following code to:\n",
    "\n",
    "- first compute the $5, 25, 50, 75, 95\\%$ quantiles of the scores for the first two dimensions\n",
    "- then find the data point whose projection is closest to each combination of quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1q = np.quantile(scores[:,0],[.05,.25,.5,.75,.95])\n",
    "s2q = np.quantile(scores[:,1],[.05,.25,.5,.75,.95])\n",
    "\n",
    "idx = np.zeros([len(s1q),len(s2q)])\n",
    "\n",
    "for i in range(len(s1q)):\n",
    "    for j in range(len(s2q)):\n",
    "        aux = ((scores[:,0] - s1q[i])**2 + (scores[:,1] - s2q[j])**2).reshape(N,1)\n",
    "        idx[i,j] = np.where(aux == min(aux))[0][0]\n",
    "\n",
    "idx = idx.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Now, add these points in red to your plot above in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Run the following code to plot the images corresponding to this grid of points. Describe the general pattern of the first (left to right) and second (down to up) principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(s1q),len(s2q),figsize=(6,6))\n",
    "for i in range(len(s1q)):\n",
    "    for j in range(len(s2q)):\n",
    "        ax[len(s2q)-1-j,i].imshow(X_threes[idx[i,j],:].reshape((28,28)), cmap='gray_r')\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try to create some artificial images, by fixing different values of the weights. This can also help to interpret the latent dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = [-1000,-500,0,500,1000]\n",
    "weight2 = 0\n",
    "\n",
    "images_pc1 = np.zeros([len(weight1),D])\n",
    "\n",
    "count = 0\n",
    "for w in weight1:   \n",
    "    images_pc1[count,:] =(pca_threes.mean_ + pca_threes.components_[0,:]*w+pca_threes.components_[1,:]*weight2)\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "fig, ax = plt.subplots(1,len(weight1),figsize=(10,6))\n",
    "for i in range(len(weight1)):\n",
    "    ax[i].imshow(images_pc1[i,:].reshape((28,28)), cmap='gray_r')\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 9 (CORE)\n",
    "\n",
    "Repeat this to describe the third principal component. Look at the histogram of its scores to decide what values of weights to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 10 (EXTRA)\n",
    "\n",
    "In lecture, we saw that we can also compute the basis vectors from an SVD decomposition of the data matrix. Use the `svd` function in `scipy.linalg` to compute the first three basis vectors and verify that they are the same (up to a change in sign -- note that the signs may be flipped because each principal component specifies a direction in the $D$-dimensional space and flipping the sign has no effect as the direction does not change). \n",
    "\n",
    "Does `PCA()` perform principal component analysis using an eigendecomposition of the empirical covariance matrix or using a SVD decomposition of the data matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 **Now, is a good point to switch driver and navigator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the Number of Components <a id='nocomponents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 11 (CORE)\n",
    "\n",
    "Next, let's investigate how many components are needed by considering how much variance is explained by each component.\n",
    "\n",
    "Note that the `pca_threes` object has an attribute `explained_variance_` (variance of each component) and `explained_variance_ratio_` (proportion of variance explained by each component). \n",
    "\n",
    "Plot both the proportion of variance explained and the cummulative proportion of variance explained. Provide a suggestion of how many components to use. How much variance is explained by the suggest number of components? Comment on why we may be able to use this number of components in relation to the total number of features.\n",
    "\n",
    "<br>\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "\n",
    "You can use `cumsum()` to compute the cummulative sum of the elements in a vector.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚩 Exercise 12 (CORE)\n",
    "\n",
    "For your selected number of components, compute the reconstruted images. Plot the reconstruction for a few images and compare with the original images. Comment on the results.  \n",
    "\n",
    "<br>\n",
    "<details><summary><b><u>Hint</b></u></summary>\n",
    "\n",
    "You can use `inverse_transform()` to decode the scores.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 **Now, is a good point to switch driver and navigator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Digits <a id='other'></a>\n",
    "\n",
    "Now, let's consider another digit. \n",
    "\n",
    "### 🚩 Exercise 13 (CORE)\n",
    "\n",
    "Perform PCA for another choice of digit. What do the first two components describe? Do some digits have better approximations than others? Comment on why this may be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4-MKAQNiloz"
   },
   "source": [
    "### Exercise 14 (EXTRA)\n",
    "\n",
    "Finally, consider now two digits of your choice (edit the code below if you wish to pick different digits).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data \n",
    "X_twodigits = np.concatenate((digits_dict['3'], digits_dict['8']))\n",
    "N, D = X_twodigits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to compute and plot the mean and some of the principle components for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfvsQJkHiMnq"
   },
   "outputs": [],
   "source": [
    "# Fit PCA\n",
    "pca_digits = PCA(n_components = 50)\n",
    "pca_digits.fit(X_twodigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean image\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(pca_digits.mean_.reshape(28, 28), cmap='gray_r')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot basis vectors\n",
    "n_plot = 5\n",
    "fig, ax = plt.subplots(1,5,figsize=(10,4))\n",
    "for n in range(n_plot):\n",
    "  ax[n].imshow(pca_digits.components_[n,:].reshape((28,28)), cmap='gray_r')\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the projection of the data in the latent space and color the data by the labels. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try also to generate artificial images and decsribe how images change along the PCs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competing the Worksheet\n",
    "\n",
    "At this point you have hopefully been able to complete all the CORE exercises and attempted the EXTRA ones. Now \n",
    "is a good time to check the reproducibility of this document by restarting the notebook's\n",
    "kernel and rerunning all cells in order.\n",
    "\n",
    "Before generating the PDF, please go to Edit -> Edit Notebook Metadata and change 'Student 1' and 'Student 2' in the **name** attribute to include your name.\n",
    "\n",
    "Once that is done and you are happy with everything, you can then run the following cell \n",
    "to generate your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to pdf mlp_week02.ipynb "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Sara Wade"
   },
   {
    "name": "Ozan Evkaya"
   }
  ],
  "colab": {
   "authorship_tag": "ABX9TyPnVLBtiMvmxzIy9XulipFP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "title": "MLPy Workshop 2: Solutions"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
